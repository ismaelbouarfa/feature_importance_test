{"cells":[{"metadata":{},"cell_type":"markdown","source":"Calling our guys !"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quick view in the dataset, clean !"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ndata = pd.read_csv('../input/train.csv')\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data visualisation**\n\n\n* Check the composition of the dataset\n* Overview of the different labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data visualisation\npredictors = ['profile pic', 'nums/length username','fullname words', 'nums/length fullname', 'name==username', 'description length', 'external URL', 'private', '#posts', '#followers', '#follows']  \nfor col in predictors: # Loop through all columns in predictors\n    if data[col].dtype == 'object':  # check if column's type is object (text)\n        data[col] = pd.Categorical(data[col]).codes  # convert text to numerical","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data**\n\nDivide the data into one set to train the model and another to test it later.\n\nAs an indication we use the linear regression to justify the passage to Random Forest.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into a training set and a testing set\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(data[predictors], data['fake'], test_size=0.3, random_state=1)\n\n#Using linear regression to check the score \nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=1)\nclf.fit(X_train, y_train)\ntrain_score = clf.score(X_train, y_train)\nprint ('train accuracy =', clf.score(X_train, y_train))\n\nfrom sklearn import model_selection\nscores = model_selection.cross_val_score(clf, data[predictors], data['fake'], scoring='accuracy', cv=5)\nprint('cross validation accuracy =', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import from: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n#Using Random Forests\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier(random_state=1)  # by default, 10 trees are used\n# your code here\nclf_rf.fit(X_train,y_train)\nprint ('train accuracy =', clf_rf.score(X_train,y_train))\n\n# Cross validation (Cross-validation is not necessary when using random forest)\nfrom sklearn.model_selection import cross_val_score\nscores_rf = cross_val_score(clf_rf, data[predictors], data['fake'], scoring='accuracy', cv=5)\nprint('cross validation accuracy =', scores_rf)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".\n.\n.\n\n**Feature Importance**\n\nThe first step in understanding the model is to identify which parameters or variables have a larger role in the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp = pd.DataFrame(clf_rf.feature_importances_, predictors, columns=['Importance'])\nfeat_imp.sort_values('Importance', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try with a GridSearch CV !"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparams = {'min_samples_leaf':list(range(1,5)),'min_samples_split':list(range(2,10,2)),\n          'n_estimators':list(range(10,50,10))}\nclf_rf2=RandomForestClassifier(random_state=1)\nclf_gs=GridSearchCV(clf_rf2, params, scoring = 'accuracy',cv=5)\nclf_gs.fit(data[predictors], data['fake'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clf_gs.best_score_)\nprint(clf_gs.best_params_)\nclf_rf3 = RandomForestClassifier(random_state=1,min_samples_leaf=4, min_samples_split=2, n_estimators=30) \nclf_rf3.fit(X_train, y_train)\nprint ('train accuracy =', clf_rf3.score(X_train, y_train))\n\nscores_rf3 = model_selection.cross_val_score(clf_rf3, data[predictors], data['fake'], scoring='accuracy', cv=5)\nprint('cross validation accuracy =',scores_rf3.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**\n\nThe feature importance of the same dataset is different when using another model !"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp = pd.DataFrame(clf_rf3.feature_importances_, predictors, columns=['Importance'])\nfeat_imp.sort_values('Importance', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Partial Plots**\n\nUnderstanding how the values of the features interferes in the decision making process."},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\n# Create the data that we will plot\npdp_description_length = pdp.pdp_isolate(model=clf_rf3, dataset=X_test, model_features=predictors, feature='#follows')\n\n# plot it\npdp.pdp_plot(pdp_description_length, '#follows')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\n# Create the data that we will plot\npdp_posts= pdp.pdp_isolate(model=clf_rf3, dataset=X_test, model_features=predictors, feature='fullname words')\n\n# plot it\npdp.pdp_plot(pdp_posts, 'fullname words')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SHAP Values**\n\nUnderstanding which features are most valuable when predicting (single prediction)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(clf_rf3)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(X_test)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[1], X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's analyse a single prediction and how it is influenced\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#SHAP\nrow_to_show = 5\ndata_for_prediction = X_test.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nclf_rf3.predict_proba(data_for_prediction_array)\n\nimport shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(clf_rf3)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\n\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}